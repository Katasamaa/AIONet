# decision_engine/llm_optimizer.py

import os
import json
import re
from openai import OpenAI

class LLMOptimizer:
    """
    –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI GPT –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–¥–∞—á ML
    –í–µ—Ä—Å–∏—è: –ü—Ä–æ—Ç–æ—Ç–∏–ø v1.0
    """
    
    def __init__(self, api_key=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
        
        Args:
            api_key: –µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        
        if not self.api_key:
            raise ValueError(
                "‚ö†Ô∏è OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω!\n"
                "–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:\n"
                "OPENAI_API_KEY=–≤–∞—à_–∫–ª—é—á"
            )
        
        self.client = OpenAI(api_key=self.api_key)
        self.model = "gpt-4o-mini"  # –î–µ—à–µ–≤–∞—è –º–æ–¥–µ–ª—å, $5 –±–µ—Å–ø–ª–∞—Ç–Ω–æ
        
        print(f"‚úÖ LLM –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.model}")
    
    def _call_llm(self, prompt, max_tokens=1024, temperature=0.3):
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã–∑–æ–≤–∞ OpenAI API
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=max_tokens,
                temperature=temperature
            )
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ OpenAI API: {str(e)}")
    
    def parse_task(self, user_description):
        """
        –ü–∞—Ä—Å–∏—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON
        
        Args:
            user_description (str): –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ
            
        Returns:
            dict: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–¥–∞—á–∏
            
        Example:
            >>> llm.parse_task("–•–æ—á—É –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ü–µ–Ω—ã –Ω–∞ –∫–≤–∞—Ä—Ç–∏—Ä—ã")
            {
                "task_type": "regression",
                "recommended_model": "RandomForestRegressor",
                ...
            }
        """
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–¥–∞—á—É –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON.

–ó–∞–¥–∞—á–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{user_description}"

–í–µ—Ä–Ω–∏ JSON —Å—Ç—Ä–æ–≥–æ –≤ —Ç–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "task_type": "classification" –∏–ª–∏ "regression",
    "data_description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∑–∞–ø—Ä–æ—Å–∞",
    "recommended_model": "–æ–¥–Ω–∞ –∏–∑ –º–æ–¥–µ–ª–µ–π –Ω–∏–∂–µ",
    "reasoning": "–ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω–∞ —ç—Ç–∞ –º–æ–¥–µ–ª—å (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
    "estimated_complexity": "low/medium/high",
    "key_features": ["—Å–ø–∏—Å–æ–∫ –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –µ—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç—ã, –∏–Ω–∞—á–µ []"],
    "target": "—Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –µ—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç–∞, –∏–Ω–∞—á–µ null"
}}

–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:
- LogisticRegression (–±—ã—Å—Ç—Ä–∞—è, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–∞—è)
- RandomForestClassifier (—Ç–æ—á–Ω–∞—è, —É—Å—Ç–æ–π—á–∏–≤–∞—è)
- GradientBoostingClassifier (–æ—á–µ–Ω—å —Ç–æ—á–Ω–∞—è, –º–µ–¥–ª–µ–Ω–Ω–∞—è)
- SVC (–¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü)
- KNeighborsClassifier (–ø—Ä–æ—Å—Ç–∞—è, –¥–ª—è –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö)

–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:
- LinearRegression (–ø—Ä–æ—Å—Ç–∞—è, –±—ã—Å—Ç—Ä–∞—è)
- Ridge (—Ä–µ–≥—É–ª—è—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –ª–∏–Ω–µ–π–Ω–∞—è)
- Lasso (–≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
- RandomForestRegressor (–Ω–µ–ª–∏–Ω–µ–π–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å)
- GradientBoostingRegressor (–æ—á–µ–Ω—å —Ç–æ—á–Ω–∞—è)

–í–ê–ñ–ù–û: 
- –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –ø—Ä–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏/–∫–ª–∞—Å—Å—ã/—Ç–∏–ø—ã ‚Üí classification
- –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –ø—Ä–æ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è/—Ü–µ–Ω—ã/–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ ‚Üí regression
- –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON, –±–µ–∑ markdown –∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π!"""

        try:
            response_text = self._call_llm(prompt, max_tokens=1024, temperature=0.3)
            
            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç markdown –µ—Å–ª–∏ GPT –¥–æ–±–∞–≤–∏–ª
            response_text = re.sub(r'```json\s*', '', response_text)
            response_text = re.sub(r'```\s*', '', response_text)
            response_text = response_text.strip()
            
            # –ü–∞—Ä—Å–∏–Ω–≥ JSON
            parsed = json.loads(response_text)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            required_fields = ["task_type", "recommended_model"]
            for field in required_fields:
                if field not in parsed:
                    return {
                        "error": f"LLM –Ω–µ –≤–µ—Ä–Ω—É–ª –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {field}",
                        "raw_response": response_text
                    }
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ task_type –≤–∞–ª–∏–¥–µ–Ω
            if parsed["task_type"] not in ["classification", "regression"]:
                parsed["task_type"] = "classification"  # fallback
            
            return parsed
            
        except json.JSONDecodeError as e:
            return {
                "error": f"LLM –≤–µ—Ä–Ω—É–ª –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON: {str(e)}",
                "raw_response": response_text if 'response_text' in locals() else "No response",
                "hint": "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –±–æ–ª–µ–µ —á–µ—Ç–∫–æ"
            }
        except Exception as e:
            return {
                "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API: {str(e)}",
                "details": str(type(e).__name__)
            }
    
    def select_best_model(self, models, task_description, data_info=None):
        """
        –í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        
        Args:
            models (list): –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –º–æ–¥–µ–ª–µ–π
            task_description (str): –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
            data_info (dict, optional): –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
            
        Returns:
            str: –ù–∞–∑–≤–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        """
        
        data_context = ""
        if data_info:
            data_context = f"\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö: {json.dumps(data_info, ensure_ascii=False)}"
        
        prompt = f"""–í—ã–±–µ—Ä–∏ –û–î–ù–£ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞—á–∏.

–ó–∞–¥–∞—á–∞: {task_description}{data_context}

–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(models)}

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º, –Ω–∞–ø—Ä–∏–º–µ—Ä: RandomForestClassifier

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã–±–æ—Ä–∞:
- –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–¥–∞—á ‚Üí Logistic/Linear
- –î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –∑–∞–¥–∞—á —Å –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å—é ‚Üí RandomForest
- –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á —Ç—Ä–µ–±—É—é—â–∏—Ö –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ ‚Üí GradientBoosting
- –î–ª—è –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö ‚Üí KNeighbors/Ridge
- –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö ‚Üí LinearRegression/LogisticRegression"""

        try:
            selected = self._call_llm(prompt, max_tokens=50, temperature=0.2)
            selected = selected.strip().split()[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –º–æ–¥–µ–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞
            if selected in models:
                return selected
            
            # –ï—Å–ª–∏ LLM –≤–µ—Ä–Ω—É–ª —á—Ç–æ-—Ç–æ —Å—Ç—Ä–∞–Ω–Ω–æ–µ, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å
            print(f"‚ö†Ô∏è LLM –≤–µ—Ä–Ω—É–ª –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—É—é –º–æ–¥–µ–ª—å '{selected}', –∏—Å–ø–æ–ª—å–∑—É—é {models[0]}")
            return models[0]
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –º–æ–¥–µ–ª–∏: {e}")
            return models[0]  # Fallback –Ω–∞ –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å
    
    def suggest_hyperparameters(self, model_name, task_type, data_size=None):
        """
        –ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏
        
        Args:
            model_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            task_type (str): –¢–∏–ø –∑–∞–¥–∞—á–∏ (classification/regression)
            data_size (int, optional): –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
            
        Returns:
            dict: –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ scikit-learn
        """
        
        size_context = f"–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: ~{data_size} –ø—Ä–∏–º–µ—Ä–æ–≤" if data_size else "–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω"
        
        prompt = f"""–ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏ scikit-learn.

–ú–æ–¥–µ–ª—å: {model_name}
–ó–∞–¥–∞—á–∞: {task_type}
{size_context}

–í–µ—Ä–Ω–∏ JSON —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä:
{{
    "n_estimators": 100,
    "max_depth": 10,
    "random_state": 42
}}

–î–ª—è LinearRegression/LogisticRegression –≤–µ—Ä–Ω–∏ –ø—Ä–æ—Å—Ç–æ {{"random_state": 42}}

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –±–µ–∑ —Ç–µ–∫—Å—Ç–∞!"""

        try:
            response_text = self._call_llm(prompt, max_tokens=500, temperature=0.3)
            response_text = re.sub(r'```json\s*', '', response_text)
            response_text = re.sub(r'```\s*', '', response_text)
            response_text = response_text.strip()
            
            params = json.loads(response_text)
            
            # –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º random_state –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
            if "random_state" not in params:
                params["random_state"] = 42
            
            return params
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            return {"random_state": 42}
    
    def interpret_results(self, metrics, model_name):
        """
        –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        
        Args:
            metrics (dict): –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏ (accuracy, mse, r2, etc.)
            model_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            
        Returns:
            str: –¢–µ–∫—Å—Ç–æ–≤–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Example:
            >>> llm.interpret_results({"accuracy": 0.95}, "RandomForest")
            "–ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã..."
        """
        
        metrics_str = json.dumps(metrics, ensure_ascii=False, indent=2)
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.

–ú–æ–¥–µ–ª—å: {model_name}
–ú–µ—Ç—Ä–∏–∫–∏:
{metrics_str}

–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è):
1. –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ (–æ—Ç–ª–∏—á–Ω–æ/—Ö–æ—Ä–æ—à–æ/—Å—Ä–µ–¥–Ω–µ/–ø–ª–æ—Ö–æ)
2. –ß—Ç–æ –æ–∑–Ω–∞—á–∞—é—Ç —ç—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
3. –ï—Å—Ç—å –ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—è
4. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é

–ü–∏—à–∏ –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º, –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤."""

        try:
            interpretation = self._call_llm(prompt, max_tokens=1000, temperature=0.5)
            return interpretation
            
        except Exception as e:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}"
    
    def generate_dataset_recommendation(self, task_type, subtask, available_datasets):
        """
        –ù–û–í–´–ô: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö
        
        Args:
            task_type (str): –¢–∏–ø –∑–∞–¥–∞—á–∏ (classification/regression)
            subtask (str): –ü–æ–¥–∑–∞–¥–∞—á–∞
            available_datasets (list): –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
            
        Returns:
            str: –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        """
        
        prompt = f"""–í—ã–±–µ—Ä–∏ –ª—É—á—à–∏–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.

–ó–∞–¥–∞—á–∞: {task_type} - {subtask}
–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã: {', '.join(available_datasets)}

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º, –Ω–∞–ø—Ä–∏–º–µ—Ä: load_iris

–ö—Ä–∏—Ç–µ—Ä–∏–∏:
- –î–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö ‚Üí –ø—Ä–æ—Å—Ç—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (iris, wine)
- –î–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∑–∞–¥–∞—á ‚Üí breast_cancer, diabetes
- –î–ª—è –±–æ–ª—å—à–∏—Ö –∑–∞–¥–∞—á ‚Üí digits, california_housing"""

        try:
            selected = self._call_llm(prompt, max_tokens=50, temperature=0.2)
            selected = selected.strip().split()[0]
            
            if selected in available_datasets:
                return selected
            
            return available_datasets[0]
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
            return available_datasets[0]


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø—Ä—è–º–æ–º –≤—ã–∑–æ–≤–µ —Ñ–∞–π–ª–∞)
if __name__ == "__main__":
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLMOptimizer...\n")
    
    try:
        llm = LLMOptimizer()
        
        # –¢–µ—Å—Ç 1: –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        print("üìù –¢–µ—Å—Ç 1: –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        result1 = llm.parse_task("–•–æ—á—É –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ü–≤–µ—Ç—ã –∏—Ä–∏—Å–∞ –ø–æ —Ä–∞–∑–º–µ—Ä—É –ª–µ–ø–µ—Å—Ç–∫–æ–≤")
        print(json.dumps(result1, ensure_ascii=False, indent=2))
        
        print("\n" + "="*50 + "\n")
        
        # –¢–µ—Å—Ç 2: –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–¥–∞—á–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
        print("üìù –¢–µ—Å—Ç 2: –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–¥–∞—á–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏")
        result2 = llm.parse_task("–ù—É–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ü–µ–Ω—ã –Ω–∞ –∫–≤–∞—Ä—Ç–∏—Ä—ã –ø–æ –ø–ª–æ—â–∞–¥–∏")
        print(json.dumps(result2, ensure_ascii=False, indent=2))
        
        print("\n" + "="*50 + "\n")
        
        # –¢–µ—Å—Ç 3: –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        print("üìù –¢–µ—Å—Ç 3: –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏")
        models = ["LinearRegression", "Ridge", "RandomForestRegressor"]
        best = llm.select_best_model(models, "–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω –Ω–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å")
        print(f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best}")
        
        print("\n‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")
        
    except ValueError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print("\nüí° –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:")
        print("OPENAI_API_KEY=sk-–≤–∞—à-–∫–ª—é—á-–∑–¥–µ—Å—å")
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")